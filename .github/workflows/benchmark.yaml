name: Benchmark check

on:
  push:
    branches:
      - '**'

jobs:
  measure-time:
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        procedure: ["move", "stop"]
        sm-version: ["0.19.0", "0.20.0"]
    env:
      benchmark_dir: ./benchmark
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Docker login
        run: echo ${{secrets.GITHUB_TOKEN}} | docker login https://ghcr.io -u ${GITHUB_ACTOR} --password-stdin
      - name: Pull and tag SM images
        run: |
          docker pull ghcr.io/netcracker/sm-dummy:${{ matrix.sm-version }}
          docker pull ghcr.io/netcracker/site-manager:${{ matrix.sm-version }}
          docker tag ghcr.io/netcracker/sm-dummy:${{ matrix.sm-version }} sm-dummy
          docker tag ghcr.io/netcracker/site-manager:${{ matrix.sm-version }} site-manager
      - name: Copy benchmark files to not git directory
        run: cp -r ./ci/benchmark ${{ env.benchmark_dir }}
      - name: Checkout tags
        run: |
          git fetch --tags
          git checkout tags/${{ matrix.sm-version }}
      - name: Run docker compose
        run: docker-compose -f ${{ env.benchmark_dir }}/docker-compose.yaml up --detach
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-sc.txt
      - name: Measure the time
        run: ${{ env.benchmark_dir }}/measure_time.sh ${{ matrix.procedure }} ${{ matrix.sm-version }}
      - name: Collect artifacts reports
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-${{ matrix.procedure }}-${{ matrix.sm-version }}
          path: report-${{ matrix.procedure }}-${{ matrix.sm-version }}.json
          retention-days: 1
      - name: Collect logs from docker-compose
        if: ${{ !cancelled() }}
        run: docker-compose -f ${{ env.benchmark_dir }}/docker-compose.yaml logs > docker-compose.log
      - name: Down docker compose
        if: ${{ !cancelled() }}
        run: docker-compose -f ${{ env.benchmark_dir }}/docker-compose.yaml down
      - name: Collect artifacts logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-compose-logs-${{ matrix.procedure }}-${{ matrix.sm-version }}
          path: docker-compose.log
          retention-days: 7

  analyze-results:
    runs-on: ubuntu-22.04
    needs: [ measure-time ]
    strategy:
      fail-fast: false
      matrix:
        procedure: ["move", "stop"]
    steps:
    - name: Download benchmark reports
      uses: actions/download-artifact@v4
      with:
        path: benchmark
        pattern: benchmark-${{ matrix.procedure }}-*
    - name: Check downloaded reports
      run: ls -R benchmark
    - name: Compare performance
      run: |
        first_run_seconds=$(cat $dir/report-${{ matrix.procedure }}-0.19.0.json | jq '.nanoseconds')
        second_run_seconds=$(cat $dir/report-${{ matrix.procedure }}-0.20.0.json | jq '.nanoseconds')
        echo "Average time for procedure ${{ matrix.procedure }} for version 0.19.0: $first_run_seconds nanoseconds"
        echo "Average time for procedure move for version 0.20.0: $second_run_seconds nanoseconds"
        score=$(bc <<< "scale=2; $second_run_seconds * 100 /$first_run_seconds")
        echo "Average score: $score%"
        delta=$(printf "%.0f" "$(bc <<< "$score - 105")")
        if (( delta > 5 )); then
          echo "Delta is too big: $delta%"
          exit 1
        fi
